import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics.pairwise import cosine_similarity
import re

# 1. ƒê·ªçc d·ªØ li·ªáu
df_books = pd.read_csv("data/Books.csv.zip", compression="zip")
df_ratings = pd.read_csv("data/Ratings.csv.zip", compression="zip")

# 2. L·ªçc s√°ch ph·ªï bi·∫øn v√† ƒë·∫£m b·∫£o kh·ªõp v·ªõi df_books
popular_books = df_ratings["ISBN"].value_counts()
popular_books = popular_books[popular_books >= 20].index
df_books = df_books[df_books["ISBN"].isin(popular_books)].copy()

# 3. X·ª≠ l√Ω missing values v√† chu·∫©n h√≥a vƒÉn b·∫£n
df_books["Book-Author"] = df_books["Book-Author"].fillna("unknown_author")
df_books["Publisher"] = df_books["Publisher"].fillna("unknown_publisher")
df_books["Book-Title"] = df_books["Book-Title"].fillna("unknown_title")

# H√†m chu·∫©n h√≥a vƒÉn b·∫£n
def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'[^\w\s]', ' ', text)  # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát
    text = re.sub(r'\s+', ' ', text).strip()  # Chu·∫©n h√≥a kho·∫£ng tr·∫Øng
    return text

# T·∫°o c·ªôt ƒë·∫∑c tr∆∞ng text
df_books["features"] = (
    df_books["Book-Title"].apply(clean_text) + " " +
    df_books["Book-Author"].apply(clean_text) + " " +
    df_books["Publisher"].apply(clean_text)
)

# 4. TF-IDF vectorization
vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)  # Gi·ªõi h·∫°n s·ªë ƒë·∫∑c tr∆∞ng
tfidf_matrix = vectorizer.fit_transform(df_books["features"])

print("Original TF-IDF shape:", tfidf_matrix.shape)

# 5. Gi·∫£m chi·ªÅu b·∫±ng TruncatedSVD
k = min(200, tfidf_matrix.shape[1] - 1)  # Ch·ªçn k h·ª£p l√Ω, tr√°nh v∆∞·ª£t qu√° s·ªë ƒë·∫∑c tr∆∞ng
svd = TruncatedSVD(n_components=k)
reduced_matrix = svd.fit_transform(tfidf_matrix)

print("Reduced TF-IDF shape (after SVD):", reduced_matrix.shape)

# 6. T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c s√°ch
cosine_sim = cosine_similarity(reduced_matrix)

# 7. T·∫°o ch·ªâ m·ª•c t√¨m ki·∫øm nhanh, x·ª≠ l√Ω tr√πng l·∫∑p
# S·ª≠ d·ª•ng ISBN ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh duy nh·∫•t, nh∆∞ng tra c·ª©u b·∫±ng ti√™u ƒë·ªÅ
df_books["Book-Title-Lower"] = df_books["Book-Title"].apply(clean_text)
indices = pd.Series(df_books.index, index=df_books["Book-Title-Lower"]).to_dict()

# 8. H√†m g·ª£i √Ω s√°ch
def get_recommendations(title, cosine_sim=cosine_sim, df=df_books, indices=indices, top_n=10):
    title_cleaned = clean_text(title)
    if title_cleaned not in indices:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y s√°ch: {title}")
        # T√¨m g·∫ßn ƒë√∫ng b·∫±ng chu·ªói ch·ª©a ti√™u ƒë·ªÅ
        matches = df[df["Book-Title-Lower"].str.contains(title_cleaned, case=False, na=False)]
        if not matches.empty:
            print("üìö G·ª£i √Ω: C√≥ th·ªÉ b·∫°n mu·ªën t√¨m m·ªôt trong c√°c s√°ch sau:")
            for _, row in matches.head(5).iterrows():
                print(f"- {row['Book-Title']} ({row['Book-Author']})")
        return pd.DataFrame()

    idx = indices[title_cleaned]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]
    book_indices = [i[0] for i in sim_scores]
    return df.iloc[book_indices][["Book-Title", "Book-Author", "Publisher"]].reset_index(drop=True)

# 9. G·ª£i √Ω th·ª≠
book_name = "Harry Potter and the Chamber of Secrets"
print(f"\nüìö G·ª£i √Ω s√°ch t∆∞∆°ng t·ª± '{book_name}':")
recommendations = get_recommendations(book_name)

if not recommendations.empty:
    for i, row in recommendations.iterrows():
        print(f"{i+1}. {row['Book-Title']} - {row['Book-Author']} ({row['Publisher']})")
