import numpy as np
import pandas as pd
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics.pairwise import cosine_similarity
from datetime import datetime, timedelta

# 1. ƒê·ªçc d·ªØ li·ªáu
df_rating = pd.read_csv("data/Ratings.csv.zip", compression="zip")
df_user = pd.read_csv("data/Users.csv.zip", compression="zip")

# Simulate a timestamp column for context (since dataset doesn't have it)
np.random.seed(42)
start_date = datetime(2023, 1, 1)
df_rating["Rating-Timestamp"] = [
    (start_date + timedelta(days=np.random.randint(0, 730))).strftime("%Y-%m-%d")
    for _ in range(len(df_rating))
]

# 2. L·ªçc ng∆∞·ªùi d√πng ho·∫°t ƒë·ªông v√† s√°ch ph·ªï bi·∫øn
active_users = df_rating["User-ID"].value_counts()
active_users = active_users[active_users >= 20].index
df_filtered = df_rating[df_rating["User-ID"].isin(active_users)]

popular_books = df_filtered["ISBN"].value_counts()
popular_books = popular_books[popular_books >= 20].index
df_filtered = df_filtered[df_filtered["ISBN"].isin(popular_books)]

# 3. Th√™m Location t·ª´ b·∫£ng user
df_filtered = df_filtered.merge(df_user[["User-ID", "Location"]], on="User-ID", how="left")

# 4. M√£ h√≥a l·∫°i UserID v√† BookID
user_mapping = {id: idx for idx, id in enumerate(df_filtered["User-ID"].unique())}
book_mapping = {isbn: idx for idx, isbn in enumerate(df_filtered["ISBN"].unique())}

df_filtered["UserID"] = df_filtered["User-ID"].map(user_mapping)
df_filtered["BookID"] = df_filtered["ISBN"].map(book_mapping)
df_filtered["Rating"] = df_filtered["Book-Rating"]

# 5. ƒê·ªãnh nghƒ©a ng·ªØ c·∫£nh (context)
context_location = "usa"
context_time = "recent"  # Ratings within the last 6 months
cutoff_date = (datetime(2024, 1, 1) - timedelta(days=180)).strftime("%Y-%m-%d")

# L·ªçc d·ªØ li·ªáu theo ng·ªØ c·∫£nh
df_context = df_filtered[
    (df_filtered["Location"].str.contains(context_location, case=False, na=False)) &
    (df_filtered["Rating-Timestamp"] >= cutoff_date)
]

# 6. T·∫°o ma tr·∫≠n ng∆∞·ªùi d√πng - s√°ch theo ng·ªØ c·∫£nh
user_item_matrix = df_context.pivot_table(
    index="UserID", columns="BookID", values="Rating", aggfunc="mean"
).fillna(0)

# 7. Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng b·∫±ng SVD
m, n = user_item_matrix.shape
k = int(np.sqrt(min(m, n)))

svd = TruncatedSVD(n_components=k)
U = svd.fit_transform(user_item_matrix)
Sigma = svd.singular_values_
VT = svd.components_

# 8. Ch·ªçn ng∆∞·ªùi d√πng test v√† ng·ªØ c·∫£nh
user_index = 10  # index trong ma tr·∫≠n
r = user_item_matrix.iloc[user_index].values.reshape(1, -1)
r_reduced = r[:, :VT.shape[1]]
Unew = np.dot(r_reduced, VT.T) / Sigma

# 9. T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng c√≥ tr·ªçng s·ªë theo ng·ªØ c·∫£nh
# Th√™m tr·ªçng s·ªë d·ª±a tr√™n s·ª± t∆∞∆°ng ƒë·ªìng c·ªßa ng·ªØ c·∫£nh (Location v√† Time)
similarities = cosine_similarity(Unew, U).flatten()

# ƒêi·ªÅu ch·ªânh ƒë·ªô t∆∞∆°ng ƒë·ªìng d·ª±a tr√™n ng·ªØ c·∫£nh
context_weights = np.ones(len(user_item_matrix))
for idx in range(len(user_item_matrix)):
    user_id = user_item_matrix.index[idx]
    user_ratings = df_context[df_context["UserID"] == user_id]
    # Tr·ªçng s·ªë cao h∆°n n·∫øu ng∆∞·ªùi d√πng c√≥ nhi·ªÅu ƒë√°nh gi√° trong ng·ªØ c·∫£nh t∆∞∆°ng t·ª±
    location_match = user_ratings["Location"].str.contains(context_location, case=False, na=False).mean()
    time_match = (user_ratings["Rating-Timestamp"] >= cutoff_date).mean()
    context_weights[idx] = 0.6 * similarities[idx] + 0.2 * location_match + 0.2 * time_match

# Ch·ªçn top 10 ng∆∞·ªùi d√πng t∆∞∆°ng t·ª±
top_10_users = [user for user in context_weights.argsort()[::-1] if user != user_index][:10]

# 10. G·ª£i √Ω s√°ch d·ª±a tr√™n c√°c ng∆∞·ªùi d√πng t∆∞∆°ng ƒë·ªìng
test_user_rated_books = set(user_item_matrix.iloc[user_index].to_numpy().nonzero()[0])
recommended_books = []
seen_books = set()

for user in top_10_users:
    user_top_books = df_context[
        (df_context["UserID"] == user) & (df_context["Rating"] > 3)
    ].sort_values(by="Rating", ascending=False)

    for _, row in user_top_books.iterrows():
        book_id = row["BookID"]
        if book_id not in seen_books and book_id not in test_user_rated_books:
            recommended_books.append((book_id, row["Rating"]))
            seen_books.add(book_id)

        if len(recommended_books) >= 10:
            break
    if len(recommended_books) >= 10:
        break

# 11. Hi·ªÉn th·ªã k·∫øt qu·∫£
recommended_books.sort(key=lambda x: x[1], reverse=True)

print(f"üìö Top 10 s√°ch ƒë∆∞·ª£c g·ª£i √Ω cho ng∆∞·ªùi d√πng trong ng·ªØ c·∫£nh (Location: {context_location}, Time: {context_time}):")
for i, (book_id, rating) in enumerate(recommended_books, 1):
    print(f"{i}. BookID: {book_id} - Rating: {rating:.2f}")
